# Twitter15 数据准备说明

## 概述

本目录包含Twitter15数据集的准备脚本，用于将原始Twitter15数据转换为AGP-MABSA项目所需的JSONL格式。

## 数据统计

- **训练集**: 3,179 样本（来自2,101张图像）
- **验证集**: 1,122 样本（来自727张图像）
- **测试集**: 1,037 样本（来自674张图像）
- **总计**: 5,338 样本
- **图像总数**: 8,288 张

### 标签分布

- **负面 (0)**: 630 样本 (11.8%)
- **中性 (1)**: 3,160 样本 (59.2%)
- **正面 (2)**: 1,548 样本 (29.0%)

## 目录结构

```
data/
├── raw/                          # 转换后的原始数据（JSONL格式）
│   ├── train.jsonl              # 训练集
│   ├── dev.jsonl                # 验证集
│   └── test.jsonl               # 测试集
├── processed/                    # 处理后的数据（LLM扩写后）
├── images/                       # 图像文件
│   └── twitter2015_images/      # Twitter2015图像（符号链接）
└── Twitter15/                    # 原始Twitter15数据
    ├── twitter2015/             # TSV和TXT格式的文本数据
    ├── twitter2015_images/      # 原始图像文件
    ├── prepare_data.py          # 数据准备脚本
    ├── verify_data.py           # 数据验证脚本
    ├── PREPARED_DATA_SUMMARY.md # 总结，不太重要
    └── README.md                # Twitter15原始说明

```

## 使用方法

### 1. 准备数据

运行数据准备脚本：

```bash
cd data/Twitter15_Process
python prepare_data.py
```

**注意**：脚本会自动从 `../Twitter15/` 读取原始数据

该脚本会：
- 读取 `twitter2015/` 目录下的TSV文件
- 转换为JSONL格式并保存到 `data/raw/` 目录
- 创建必要的目录结构
- 为图像文件创建符号链接

### 2. 验证数据

运行数据验证脚本：

```bash
cd data/Twitter15_Process
python verify_data.py
```

该脚本会：
- 检查JSONL文件的完整性
- 验证所有字段是否存在
- 检查图像文件是否存在
- 统计标签分布
- 显示样本示例

## 数据格式

### JSONL格式说明

每行是一个JSON对象，包含以下字段：

```json
{
  "sample_id": "twitter15_train_000001",
  "text": "RT @ ltsChuckBass : Chuck Bass is everything # MCM",
  "aspect": "Chuck Bass",
  "image_paths": ["twitter2015_images/1860693.jpg"],
  "label": 2,
  "pair_id": "twitter15_train_1860693"
}
```

### 字段说明

| 字段 | 类型 | 说明 |
|------|------|------|
| `sample_id` | string | 唯一样本标识符，格式: `twitter15_{split}_{序号}` |
| `text` | string | 完整的推文文本 |
| `aspect` | string | 目标实体/方面 |
| `image_paths` | list | 图像路径列表（相对于`data/images/`） |
| `label` | int | 情感标签：0=负面，1=中性，2=正面 |
| `pair_id` | string | 图文对标识，同一张图片的不同样本共享相同的前缀 |

### 与原始格式的映射

原始Twitter15 TSV格式：
```
index	label	image_id	text_with_mask	target_entity
1	2	1860693.jpg	RT @ ltsChuckBass : $T$ is everything # MCM	Chuck Bass
```

转换后的JSONL格式：
- `$T$` 被替换为实际的 `target_entity`
- `image_id` 变为 `image_paths` 列表
- 添加了 `sample_id` 和 `pair_id` 用于唯一标识

## 注意事项

1. **图像路径**: 图像文件通过符号链接指向原始位置，避免重复存储
2. **同一图片多个样本**: 同一张图片可能对应多个目标实体，每个都是独立的样本
3. **标签格式**: 确保标签为整数 0/1/2，而非原始txt文件中的 -1/0/1
4. **文本编码**: 所有文件使用UTF-8编码

## 下一步

准备好原始数据后，可以：

1. **直接训练**: 使用 `data/raw/` 中的数据进行训练
2. **LLM扩写**: 运行 `src/data/llm_expansion.py` 生成包含 `aspect_desc` 字段的扩写数据
3. **数据探索**: 使用验证脚本查看数据分布和样本示例

## 常见问题

### Q: 图像文件找不到？
A: 检查符号链接是否正确创建：
```bash
ls -la data/images/twitter2015_images
```

### Q: 如何添加 aspect_desc 字段？
A: 运行LLM扩写脚本（需要先实现该脚本）：
```bash
python src/data/llm_expansion.py
```

### Q: 如何修改数据格式？
A: 编辑 `prepare_data.py` 中的 `convert_to_jsonl_format` 函数。

## 参考文献

原始数据来源：
> Yu, J., & Jiang, J. (2019). Adapting BERT for Target-Oriented Multimodal Sentiment Classification. *IJCAI 2019*.

数据集链接: [原始README](README.md)
